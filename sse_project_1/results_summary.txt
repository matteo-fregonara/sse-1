Starting training benchmark - 30 iterations
========================================

Running iteration 1 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 59.032958984375 for 3.6229098 sec of execution.
Results saved to results\pytorch_iter1_20250223_004027.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 00:41:34.234449: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 00:41:35.554401: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 00:41:39.103280: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 170.10028076171875 for 9.832956 sec of execution.
Results saved to results\tensorflow_iter1_20250223_004027.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 39.61102294921875 for 2.2168734 sec of execution.
Results saved to results\jax_iter1_20250223_004027.csv
Waiting 60 seconds...

Running iteration 2 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 40.1390380859375 for 2.6218677 sec of execution.
Results saved to results\pytorch_iter2_20250223_004343.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 00:44:49.030538: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 00:44:49.712572: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 00:44:51.399499: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 891us/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 109.73541259765625 for 6.833908 sec of execution.
Results saved to results\tensorflow_iter2_20250223_004343.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 29.74029541015625 for 1.8194331 sec of execution.
Results saved to results\jax_iter2_20250223_004343.csv
Waiting 60 seconds...

Running iteration 3 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 37.1605224609375 for 2.624537 sec of execution.
Results saved to results\pytorch_iter3_20250223_004655.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 00:48:01.003238: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 00:48:01.701950: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 00:48:03.392226: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 106.02581787109375 for 7.030524 sec of execution.
Results saved to results\tensorflow_iter3_20250223_004655.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 30.2003173828125 for 1.8217859 sec of execution.
Results saved to results\jax_iter3_20250223_004655.csv
Waiting 60 seconds...

Running iteration 4 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 37.2662353515625 for 2.6217775 sec of execution.
Results saved to results\pytorch_iter4_20250223_005007.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 00:51:13.027485: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 00:51:13.695132: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 00:51:15.354881: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 110.521484375 for 6.8267 sec of execution.
Results saved to results\tensorflow_iter4_20250223_005007.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 30.99017333984375 for 1.8196764 sec of execution.
Results saved to results\jax_iter4_20250223_005007.csv
Waiting 60 seconds...

Running iteration 5 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 45.18621826171875 for 2.812479 sec of execution.
Results saved to results\pytorch_iter5_20250223_005319.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 00:54:24.995977: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 00:54:25.659353: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 00:54:27.308735: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 751us/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 107.02130126953125 for 6.828461 sec of execution.
Results saved to results\tensorflow_iter5_20250223_005319.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 31.246337890625 for 1.8102455 sec of execution.
Results saved to results\jax_iter5_20250223_005319.csv
Waiting 60 seconds...

Running iteration 6 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 38.67974853515625 for 2.6203947 sec of execution.
Results saved to results\pytorch_iter6_20250223_005631.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 00:57:36.957277: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 00:57:37.627720: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 00:57:39.299357: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 111.8651123046875 for 6.8257904 sec of execution.
Results saved to results\tensorflow_iter6_20250223_005631.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 29.76153564453125 for 1.8181099 sec of execution.
Results saved to results\jax_iter6_20250223_005631.csv
Waiting 60 seconds...

Running iteration 7 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 37.9410400390625 for 2.6267903 sec of execution.
Results saved to results\pytorch_iter7_20250223_005943.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 01:00:48.935081: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 01:00:49.588125: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 01:00:51.229217: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 909us/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 103.291015625 for 6.8292603 sec of execution.
Results saved to results\tensorflow_iter7_20250223_005943.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 29.9073486328125 for 1.820576 sec of execution.
Results saved to results\jax_iter7_20250223_005943.csv
Waiting 60 seconds...

Running iteration 8 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 38.3253173828125 for 2.621872 sec of execution.
Results saved to results\pytorch_iter8_20250223_010255.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 01:04:01.012400: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 01:04:01.690956: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 01:04:03.357445: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 893us/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 106.71514892578125 for 6.830108 sec of execution.
Results saved to results\tensorflow_iter8_20250223_010255.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 30.38116455078125 for 1.8217268 sec of execution.
Results saved to results\jax_iter8_20250223_010255.csv
Waiting 60 seconds...

Running iteration 9 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 38.31976318359375 for 2.6105747 sec of execution.
Results saved to results\pytorch_iter9_20250223_010607.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 01:07:13.049179: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 01:07:13.730047: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 01:07:15.405294: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 999us/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 107.482177734375 for 7.0310445 sec of execution.
Results saved to results\tensorflow_iter9_20250223_010607.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 31.11810302734375 for 1.8193848 sec of execution.
Results saved to results\jax_iter9_20250223_010607.csv
Waiting 60 seconds...

Running iteration 10 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 39.7962646484375 for 2.6273181 sec of execution.
Results saved to results\pytorch_iter10_20250223_010919.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 01:10:25.012511: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 01:10:25.671647: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 01:10:27.328669: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 907us/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 104.804443359375 for 6.8347464 sec of execution.
Results saved to results\tensorflow_iter10_20250223_010919.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 28.38543701171875 for 1.8251351 sec of execution.
Results saved to results\jax_iter10_20250223_010919.csv
Waiting 60 seconds...

Running iteration 11 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 45.2945556640625 for 2.616305 sec of execution.
Results saved to results\pytorch_iter11_20250223_011231.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 01:13:36.985623: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 01:13:37.661563: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 01:13:39.311620: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 107.15447998046875 for 6.8319354 sec of execution.
Results saved to results\tensorflow_iter11_20250223_011231.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 30.38726806640625 for 1.8209405 sec of execution.
Results saved to results\jax_iter11_20250223_011231.csv
Waiting 60 seconds...

Running iteration 12 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 38.00390625 for 2.6216269 sec of execution.
Results saved to results\pytorch_iter12_20250223_011543.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 01:16:48.951737: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 01:16:49.612667: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 01:16:51.234683: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 108.08984375 for 6.8310347 sec of execution.
Results saved to results\tensorflow_iter12_20250223_011543.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 28.955078125 for 1.8205571 sec of execution.
Results saved to results\jax_iter12_20250223_011543.csv
Waiting 60 seconds...

Running iteration 13 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 38.1197509765625 for 2.6120083 sec of execution.
Results saved to results\pytorch_iter13_20250223_011855.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 01:20:00.977948: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 01:20:01.680986: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 01:20:03.368172: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 109.80889892578125 for 7.0180373 sec of execution.
Results saved to results\tensorflow_iter13_20250223_011855.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 30.3231201171875 for 1.8193643 sec of execution.
Results saved to results\jax_iter13_20250223_011855.csv
Waiting 60 seconds...

Running iteration 14 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 40.4932861328125 for 2.6215868 sec of execution.
Results saved to results\pytorch_iter14_20250223_012207.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 01:23:12.957253: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 01:23:13.624992: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 01:23:15.290846: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 107.1114501953125 for 6.8277864 sec of execution.
Results saved to results\tensorflow_iter14_20250223_012207.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 27.9871826171875 for 1.8232552 sec of execution.
Results saved to results\jax_iter14_20250223_012207.csv
Waiting 60 seconds...

Running iteration 15 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 38.4739990234375 for 2.6254644 sec of execution.
Results saved to results\pytorch_iter15_20250223_012519.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 01:26:24.942699: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 01:26:25.608322: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 01:26:27.245664: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 890us/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 106.41571044921875 for 6.8325796 sec of execution.
Results saved to results\tensorflow_iter15_20250223_012519.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 30.16815185546875 for 1.8150744 sec of execution.
Results saved to results\jax_iter15_20250223_012519.csv
Waiting 60 seconds...

Running iteration 16 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 38.182861328125 for 2.62161 sec of execution.
Results saved to results\pytorch_iter16_20250223_012831.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 01:29:36.953318: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 01:29:37.616104: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 01:29:39.267812: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 109.89404296875 for 6.832174 sec of execution.
Results saved to results\tensorflow_iter16_20250223_012831.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 30.40191650390625 for 1.8245091 sec of execution.
Results saved to results\jax_iter16_20250223_012831.csv
Waiting 60 seconds...

Running iteration 17 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 39.52130126953125 for 2.623842 sec of execution.
Results saved to results\pytorch_iter17_20250223_013143.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 01:32:48.971740: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 01:32:49.634887: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 01:32:51.285378: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 105.66021728515625 for 6.828721 sec of execution.
Results saved to results\tensorflow_iter17_20250223_013143.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 29.8240966796875 for 1.8234317 sec of execution.
Results saved to results\jax_iter17_20250223_013143.csv
Waiting 60 seconds...

Running iteration 18 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 38.3045654296875 for 2.6267698 sec of execution.
Results saved to results\pytorch_iter18_20250223_013455.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 01:36:00.904668: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 01:36:01.559264: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 01:36:03.200022: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 836us/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 107.1038818359375 for 6.8248243 sec of execution.
Results saved to results\tensorflow_iter18_20250223_013455.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 31.4420166015625 for 1.8242853 sec of execution.
Results saved to results\jax_iter18_20250223_013455.csv
Waiting 60 seconds...

Running iteration 19 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 37.7742919921875 for 2.6217551 sec of execution.
Results saved to results\pytorch_iter19_20250223_013807.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 01:39:12.973285: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 01:39:13.671492: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 01:39:15.357057: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 117.5235595703125 for 7.030218 sec of execution.
Results saved to results\tensorflow_iter19_20250223_013807.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 32.031005859375 for 2.0102303 sec of execution.
Results saved to results\jax_iter19_20250223_013807.csv
Waiting 60 seconds...

Running iteration 20 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 40.0535888671875 for 2.8268561 sec of execution.
Results saved to results\pytorch_iter20_20250223_014119.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 01:42:25.087488: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 01:42:25.794841: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 01:42:27.543822: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 963us/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 108.35546875 for 7.034566 sec of execution.
Results saved to results\tensorflow_iter20_20250223_014119.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 34.73443603515625 for 2.0247724 sec of execution.
Results saved to results\jax_iter20_20250223_014119.csv
Waiting 60 seconds...

Running iteration 21 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 38.19744873046875 for 2.6211367 sec of execution.
Results saved to results\pytorch_iter21_20250223_014431.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 01:45:37.022696: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 01:45:37.689806: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 01:45:39.362041: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 107.8287353515625 for 6.82266 sec of execution.
Results saved to results\tensorflow_iter21_20250223_014431.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 30.14434814453125 for 1.8192229 sec of execution.
Results saved to results\jax_iter21_20250223_014431.csv
Waiting 60 seconds...

Running iteration 22 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 39.67828369140625 for 2.6223264 sec of execution.
Results saved to results\pytorch_iter22_20250223_014743.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 01:48:48.945292: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 01:48:49.618759: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 01:48:51.260751: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 105.46343994140625 for 6.8283553 sec of execution.
Results saved to results\tensorflow_iter22_20250223_014743.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 31.29718017578125 for 1.8208234 sec of execution.
Results saved to results\jax_iter22_20250223_014743.csv
Waiting 60 seconds...

Running iteration 23 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 38.7919921875 for 2.6194646 sec of execution.
Results saved to results\pytorch_iter23_20250223_015055.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 01:52:00.896440: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 01:52:01.552670: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 01:52:03.212804: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 955us/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 949us/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 105.68255615234375 for 6.8302546 sec of execution.
Results saved to results\tensorflow_iter23_20250223_015055.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 32.96990966796875 for 2.018982 sec of execution.
Results saved to results\jax_iter23_20250223_015055.csv
Waiting 60 seconds...

Running iteration 24 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 36.84600830078125 for 2.620021 sec of execution.
Results saved to results\pytorch_iter24_20250223_015407.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 01:55:12.946859: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 01:55:13.620039: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 01:55:15.292720: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 107.3707275390625 for 6.8274436 sec of execution.
Results saved to results\tensorflow_iter24_20250223_015407.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 29.84698486328125 for 1.818239 sec of execution.
Results saved to results\jax_iter24_20250223_015407.csv
Waiting 60 seconds...

Running iteration 25 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 36.51031494140625 for 2.6260083 sec of execution.
Results saved to results\pytorch_iter25_20250223_015719.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 01:58:24.934715: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 01:58:25.620535: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 01:58:27.311933: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 967us/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 103.252197265625 for 6.8272552 sec of execution.
Results saved to results\tensorflow_iter25_20250223_015719.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 28.27001953125 for 1.8245095 sec of execution.
Results saved to results\jax_iter25_20250223_015719.csv
Waiting 60 seconds...

Running iteration 26 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 36.27972412109375 for 2.618859 sec of execution.
Results saved to results\pytorch_iter26_20250223_020031.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 02:01:37.042446: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 02:01:37.722520: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 02:01:39.384239: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 108.2696533203125 for 6.8310227 sec of execution.
Results saved to results\tensorflow_iter26_20250223_020031.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 28.90283203125 for 1.8201547 sec of execution.
Results saved to results\jax_iter26_20250223_020031.csv
Waiting 60 seconds...

Running iteration 27 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 40.11907958984375 for 2.6212852 sec of execution.
Results saved to results\pytorch_iter27_20250223_020343.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 02:04:48.993322: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 02:04:49.644434: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 02:04:51.264172: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 106.50140380859375 for 6.837044 sec of execution.
Results saved to results\tensorflow_iter27_20250223_020343.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 30.2130126953125 for 1.8194872 sec of execution.
Results saved to results\jax_iter27_20250223_020343.csv
Waiting 60 seconds...

Running iteration 28 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 38.1514892578125 for 2.6218832 sec of execution.
Results saved to results\pytorch_iter28_20250223_020655.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 02:08:00.934506: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 02:08:01.609159: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 02:08:03.237519: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 985us/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 107.36920166015625 for 6.8225913 sec of execution.
Results saved to results\tensorflow_iter28_20250223_020655.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 29.92877197265625 for 1.8215103 sec of execution.
Results saved to results\jax_iter28_20250223_020655.csv
Waiting 60 seconds...

Running iteration 29 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 37.41888427734375 for 2.6237607 sec of execution.
Results saved to results\pytorch_iter29_20250223_021007.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 02:11:12.913925: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 02:11:13.579454: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 02:11:15.232277: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 881us/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 105.73858642578125 for 6.8326783 sec of execution.
Results saved to results\tensorflow_iter29_20250223_021007.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 30.96929931640625 for 1.8189782 sec of execution.
Results saved to results\jax_iter29_20250223_021007.csv
Waiting 60 seconds...

Running iteration 30 of 30
----------------------------------------
Running PyTorch training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
Energy consumption in joules: 37.46038818359375 for 2.6220925 sec of execution.
Results saved to results\pytorch_iter30_20250223_021319.csv
Waiting 60 seconds...
Running TensorFlow training...
Training PyTorch model on CPU...
Epoch 1/10 - loss: 0.6092 - accuracy: 0.7190
Epoch 2/10 - loss: 0.4272 - accuracy: 0.9090
Epoch 3/10 - loss: 0.2667 - accuracy: 0.9510
Epoch 4/10 - loss: 0.1783 - accuracy: 0.9650
Epoch 5/10 - loss: 0.1335 - accuracy: 0.9780
Epoch 6/10 - loss: 0.1034 - accuracy: 0.9840
Epoch 7/10 - loss: 0.0845 - accuracy: 0.9900
Epoch 8/10 - loss: 0.0698 - accuracy: 0.9930
Epoch 9/10 - loss: 0.0602 - accuracy: 0.9940
Epoch 10/10 - loss: 0.0543 - accuracy: 0.9930
2025-02-23 02:14:24.930024: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-23 02:14:25.598939: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Training TensorFlow model on CPU...
C:\Users\matte\PycharmProjects\sse_project_1\.venv\lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-02-23 02:14:27.233032: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
TensorFlow is using: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
Epoch 1/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.5923 - loss: 0.6643
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.8792 - loss: 0.4826
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9287 - loss: 0.3188
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9448 - loss: 0.2098
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9642 - loss: 0.1507
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9833 - loss: 0.1170
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0953
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9929 - loss: 0.0796
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.9934 - loss: 0.0677
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9950 - loss: 0.0584
Energy consumption in joules: 109.7745361328125 for 6.834426 sec of execution.
Results saved to results\tensorflow_iter30_20250223_021319.csv
Waiting 60 seconds...
Running Jax training...
JAX is using: [CpuDevice(id=0)]
Training JAX/Flax model on CPU...
Epoch 1/10 - loss: 0.5858 - accuracy: 0.7500
Epoch 2/10 - loss: 0.4226 - accuracy: 0.8931
Epoch 3/10 - loss: 0.2832 - accuracy: 0.9446
Epoch 4/10 - loss: 0.1940 - accuracy: 0.9647
Epoch 5/10 - loss: 0.1434 - accuracy: 0.9748
Epoch 6/10 - loss: 0.1123 - accuracy: 0.9798
Epoch 7/10 - loss: nan - accuracy: 0.5081
Epoch 8/10 - loss: nan - accuracy: 0.4879
Epoch 9/10 - loss: nan - accuracy: 0.4879
Epoch 10/10 - loss: nan - accuracy: 0.4879
Energy consumption in joules: 26.68524169921875 for 1.8195679 sec of execution.
Results saved to results\jax_iter30_20250223_021319.csv
Waiting 60 seconds...

========================================
Benchmark completed - all 30 iterations finished
Results saved to the 'results' directory
(.venv) PS C:\Users\matte\PycharmProjects\sse_project_1>

